{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de5d11b-6b41-42d7-a229-0f6448b47b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 2.7.0\n",
      "google-cloud-aiplatform==1.44.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! pip3 freeze | grep aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24171ab7-0d8f-4fcf-8f1d-99e7c77b53fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "import kfp\n",
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import Artifact, Dataset, Input, Metrics, Model, Output, component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd328827-dca8-41cc-bdd5-0cd299aa1a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp.dsl import ClassificationMetrics\n",
    "from typing import NamedTuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd1aa03-18c5-4323-ba9e-3ecd223169e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'kubeflow-mlops-410520' # replace with project ID\n",
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'vertex-pipelines'\n",
    "SERIES = 'dev'\n",
    "\n",
    "# gcs bucket\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "BUCKET_URI = f\"gs://{PROJECT_ID}-bucket\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b1f8f5-e234-4de7-ab23-067fd0ed1c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6683c9-d799-4cfb-b3e9-1cc023e5d030",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/kfp/dsl/component_decorator.py:119: FutureWarning: Python 3.7 has reached end-of-life. The default base_image used by the @dsl.component decorator will switch from 'python:3.7' to 'python:3.8' on April 23, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.8.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "@component(\n",
    "    packages_to_install = [\n",
    "        \"pandas==1.3.4\",\n",
    "        \"scikit-learn==1.0.1\",\n",
    "    ],\n",
    ")\n",
    "def get_data(\n",
    "    dataset_train: Output[Dataset],\n",
    "    dataset_test: Output[Dataset],\n",
    "):\n",
    "\n",
    "    from sklearn import datasets\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "    # dataset https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "    data_raw = datasets.load_breast_cancer()\n",
    "    data = pd.DataFrame(data_raw.data, columns=data_raw.feature_names)\n",
    "    data[\"target\"] = data_raw.target\n",
    "\n",
    "    train, test = tts(data, test_size=0.3)\n",
    "\n",
    "    train.to_csv(dataset_train.path)\n",
    "    test.to_csv(dataset_test.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666b996-a1b6-4c14-ac94-b5e8540eaeca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9adaa085-aa3c-4852-975b-5e5a8ce0d5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install = [\n",
    "        \n",
    "        \"xgboost==1.6.2\",\n",
    "        \"pandas==1.3.5\",\n",
    "        \"joblib==1.1.0\",\n",
    "        \"scikit-learn==1.0.2\",\n",
    "        \"pickle5==0.0.12\",\n",
    "        \"joblib==1.1.0\",\n",
    "    ],\n",
    ")\n",
    "def train_model(\n",
    "    dataset: Input[Dataset],\n",
    "    model_artifact: Output[Model]\n",
    "):\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    import pandas as pd\n",
    "    import pickle5 as pickle\n",
    "    import os\n",
    "    #import datetime\n",
    "    import subprocess\n",
    "    from pathlib import Path\n",
    "    import joblib\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "    \n",
    "    \n",
    "    data = pd.read_csv(dataset.path)\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        objective=\"binary:logistic\"\n",
    "    )\n",
    "    model.fit(\n",
    "        data.drop(columns=[\"target\"]),\n",
    "        data.target,\n",
    "    )\n",
    "\n",
    "    score = model.score(\n",
    "        data.drop(columns=[\"target\"]),\n",
    "        data.target,\n",
    "    )\n",
    "\n",
    "    model_artifact.metadata[\"train_score\"] = float(score)\n",
    "    model_artifact.metadata[\"framework\"] = \"XGBoost\"\n",
    "    os.makedirs(model_artifact.path, exist_ok=True)\n",
    "    joblib.dump(model, os.path.join(model_artifact.path, \"model.joblib\"))\n",
    "    print(model_artifact.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e21d8ec0-5b03-424d-97c5-c7462648054b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "       \n",
    "\n",
    "@component(\n",
    "    packages_to_install = [\n",
    "        \n",
    "        \"xgboost==1.6.2\",\n",
    "        \"pandas==1.3.5\",\n",
    "        \"joblib==1.1.0\",\n",
    "        \"scikit-learn==1.0.2\",\n",
    "        \"google-cloud-storage==2.13.0\",\n",
    "    ],\n",
    ")\n",
    "def eval_model(\n",
    "    test_set: Input[Dataset],\n",
    "    xgb_model: Input[Model],\n",
    "    metrics: Output[ClassificationMetrics],\n",
    "    smetrics: Output[Metrics],\n",
    "    bucket_name: str,\n",
    ") -> NamedTuple(\"Outputs\", [(\"deploy\", str)]):\n",
    "    from xgboost import XGBClassifier\n",
    "    import pandas as pd\n",
    "\n",
    "    data = pd.read_csv(test_set.path)\n",
    "    model = XGBClassifier()\n",
    "    \n",
    "    from google.cloud import storage\n",
    "    import joblib\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob_path = xgb_model.uri.replace(\"gs://\" + bucket_name + \"/\", \"\")\n",
    "    smetrics.log_metric(\"blob_path\", str(blob_path))\n",
    "\n",
    "    blob = bucket.blob(blob_path + \"/model.joblib\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    with blob.open(mode=\"rb\") as file:\n",
    "        model = joblib.load(file)\n",
    "    #model.load_model(xgb_model.path)\n",
    "    \n",
    "\n",
    "    score = model.score(\n",
    "        data.drop(columns=[\"target\"]),\n",
    "        data.target,\n",
    "    )\n",
    "\n",
    "    from sklearn.metrics import roc_curve\n",
    "    y_scores =  model.predict_proba(data.drop(columns=[\"target\"]))[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(\n",
    "         y_true=data.target.to_numpy(), y_score=y_scores, pos_label=True\n",
    "    )\n",
    "    metrics.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    y_pred = model.predict(data.drop(columns=[\"target\"]))\n",
    "\n",
    "    metrics.log_confusion_matrix(\n",
    "       [\"False\", \"True\"],\n",
    "       confusion_matrix(\n",
    "           data.target, y_pred\n",
    "       ).tolist()\n",
    "    )\n",
    "\n",
    "    xgb_model.metadata[\"test_score\"] = float(score)\n",
    "    smetrics.log_metric(\"score\", float(score))\n",
    "\n",
    "\n",
    "    deploy = \"true\"\n",
    "    #compare threshold or to previous\n",
    "\n",
    "    return (deploy,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc7444d1-93e8-45aa-8b7b-2674a7202515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform==1.25.0\"],\n",
    ")\n",
    "def deploy_xgboost_model(\n",
    "    model: Input[Model],\n",
    "    project_id: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model],\n",
    "):\n",
    "    \"\"\"Deploys an XGBoost model to Vertex AI Endpoint.\n",
    "\n",
    "    Args:\n",
    "        model: The model to deploy.\n",
    "        project_id: The project ID of the Vertex AI Endpoint.\n",
    "\n",
    "    Returns:\n",
    "        vertex_endpoint: The deployed Vertex AI Endpoint.\n",
    "        vertex_model: The deployed Vertex AI Model.\n",
    "    \"\"\"\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    aiplatform.init(project=project_id)\n",
    "\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"breast-cancer-xgb-classification\",\n",
    "        artifact_uri=model.uri,\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-6:latest\",\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "194b4eab-36ae-4e88-a16f-65d74f0bb3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME=\"gs://\" + PROJECT_ID + \"-bucket\"\n",
    "PIPELINE_ROOT = BUCKET_NAME + \"/pipeline_root/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "947dd179-3661-4223-8c83-b3b7a8ba5d04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32293/1289652284.py:16: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
      "  with dsl.Condition(\n"
     ]
    }
   ],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT + \"xgboost-pipeline-v2\",\n",
    "    # A name for the pipeline. Use to determine the pipeline Context.\n",
    "    name=\"xgboost-pipeline-with-deployment-v2\",\n",
    ")\n",
    "def pipeline():\n",
    "    dataset_op = get_data()\n",
    "    training_op = train_model(dataset = dataset_op.outputs[\"dataset_train\"])\n",
    "    eval_op = eval_model(\n",
    "        test_set=dataset_op.outputs[\"dataset_test\"],\n",
    "        xgb_model=training_op.outputs[\"model_artifact\"],\n",
    "        bucket_name = \"kubeflow-mlops-410520-bucket\"\n",
    "    )\n",
    "\n",
    "    with dsl.Condition(\n",
    "        eval_op.outputs[\"deploy\"] == \"true\",\n",
    "        name=\"deploy\",\n",
    "    ):\n",
    "\n",
    "      deploy_op = deploy_xgboost_model(model = training_op.outputs[\"model_artifact\"],\n",
    "                         project_id = PROJECT_ID,\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "55eb3abe-672c-4352-afb0-ee0d008fa0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"pipeline-breast-cancer.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3b639c-ecff-40a6-92a2-8a52f3926c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "\n",
    "\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"breast-cancer-demo-pipeline\",\n",
    "    template_path=\"pipeline-breast-cancer.yaml\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
