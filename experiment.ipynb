{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de5d11b-6b41-42d7-a229-0f6448b47b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 2.7.0\n",
      "google-cloud-aiplatform==1.44.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! pip3 freeze | grep aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbbfac67-6aad-4c90-99b4-009f6193bd97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: grep [OPTION]... PATTERNS [FILE]...\n",
      "Try 'grep --help' for more information.\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/commands/freeze.py\", line 107, in run\n",
      "    sys.stdout.write(line + \"\\n\")\n",
      "BrokenPipeError: [Errno 32] Broken pipe\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 freeze | grep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24171ab7-0d8f-4fcf-8f1d-99e7c77b53fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "import kfp\n",
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import Artifact, Dataset, Input, Metrics, Model, Output, component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd328827-dca8-41cc-bdd5-0cd299aa1a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp.dsl import ClassificationMetrics\n",
    "from typing import NamedTuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd1aa03-18c5-4323-ba9e-3ecd223169e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'kubeflow-mlops-410520' # replace with project ID\n",
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'vertex-pipelines'\n",
    "SERIES = 'dev'\n",
    "\n",
    "# gcs bucket\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "BUCKET_URI = f\"gs://{PROJECT_ID}-bucket\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b1f8f5-e234-4de7-ab23-067fd0ed1c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6683c9-d799-4cfb-b3e9-1cc023e5d030",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/kfp/dsl/component_decorator.py:119: FutureWarning: Python 3.7 has reached end-of-life. The default base_image used by the @dsl.component decorator will switch from 'python:3.7' to 'python:3.8' on April 23, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.8.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "@component(\n",
    "    packages_to_install = [\n",
    "        \"pandas==1.3.4\",\n",
    "        \"scikit-learn==1.0.1\",\n",
    "    ],\n",
    ")\n",
    "def get_data(\n",
    "    dataset_train: Output[Dataset],\n",
    "    dataset_test: Output[Dataset],\n",
    "):\n",
    "\n",
    "    from sklearn import datasets\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "    # dataset https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "    data_raw = datasets.load_breast_cancer()\n",
    "    data = pd.DataFrame(data_raw.data, columns=data_raw.feature_names)\n",
    "    data[\"target\"] = data_raw.target\n",
    "\n",
    "    train, test = tts(data, test_size=0.3)\n",
    "\n",
    "    train.to_csv(dataset_train.path)\n",
    "    test.to_csv(dataset_test.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666b996-a1b6-4c14-ac94-b5e8540eaeca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9adaa085-aa3c-4852-975b-5e5a8ce0d5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install = [\n",
    "        \n",
    "        \"xgboost==1.6.2\",\n",
    "        \"pandas==1.3.5\",\n",
    "        \"joblib==1.1.0\",\n",
    "        \"scikit-learn==1.0.2\",\n",
    "        \"pickle5==0.0.12\",\n",
    "        \"joblib==1.1.0\",\n",
    "    ],\n",
    ")\n",
    "def train_model(\n",
    "    dataset: Input[Dataset],\n",
    "    model_artifact: Output[Model]\n",
    "):\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    import pandas as pd\n",
    "    import pickle5 as pickle\n",
    "    import os\n",
    "    #import datetime\n",
    "    import subprocess\n",
    "    from pathlib import Path\n",
    "    import joblib\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "    \n",
    "    \n",
    "    data = pd.read_csv(dataset.path)\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        objective=\"binary:logistic\"\n",
    "    )\n",
    "    model.fit(\n",
    "        data.drop(columns=[\"target\"]),\n",
    "        data.target,\n",
    "    )\n",
    "\n",
    "    score = model.score(\n",
    "        data.drop(columns=[\"target\"]),\n",
    "        data.target,\n",
    "    )\n",
    "\n",
    "    model_artifact.metadata[\"train_score\"] = float(score)\n",
    "    model_artifact.metadata[\"framework\"] = \"XGBoost\"\n",
    "    os.makedirs(model_artifact.path, exist_ok=True)\n",
    "    joblib.dump(model, os.path.join(model_artifact.path, \"model.joblib\"))\n",
    "    print(model_artifact.path)\n",
    "    #model_filename = 'xgb_model.pkl'\n",
    "\n",
    "    #model.save_model(model_artifact.path + \"/xgb_model.pkl\")\n",
    "    \n",
    "    #model_filename = 'xgb_model.pkl'\n",
    "    # MODEL_DIR = model_artifact.path #gcs_path_to_local_path(os.environ[\"AIP_MODEL_DIR\"])\n",
    "    # MODEL_PATH = MODEL_DIR + \"/model.bst\"\n",
    "    # print(\"saving model to \" + MODEL_PATH) \n",
    "    # if not Path(MODEL_DIR).exists():\n",
    "    #     Path(MODEL_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    # joblib.dump(model, MODEL_PATH) \n",
    "    # model.save_model(MODEL_PATH)\n",
    "#     pickle.dump(model, open(model_filename, \"wb\"))\n",
    "        \n",
    "#     EXPORT_PATH = os.path.join(\n",
    "#         model_artifact.path, datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "    \n",
    "#     gcs_model_path = '{}/{}'.format(EXPORT_PATH, model_filename)\n",
    "#     subprocess.check_call(['gsutil', 'cp', model_filename, gcs_model_path])\n",
    "#     print('Saved model in: {}'.format(gcs_model_path))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be81eb5-0c6d-45db-a3c3-e131a960c9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d2c248-4fdc-4b90-b0e4-7259a9e56ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud import storage\n",
    "# import joblib\n",
    "# client = storage.Client()\n",
    "# bucket = client.get_bucket(\"kubeflow-mlops-410520-bucket\")\n",
    "# blob = bucket.blob(\"gs://kubeflow-mlops-410520-bucket/pipeline_root/xgboost-pipeline/990864364836/xgboost-pipeline-with-deployment-20240327150548/train-model_4480642443057823744/model_artifact/model.bst\")\n",
    "# with blob.open(mode=\"rb\") as file:\n",
    "#     model = joblib.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e21d8ec0-5b03-424d-97c5-c7462648054b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @component(\n",
    "#     packages_to_install = [\n",
    "#         \"pandas==1.3.4\",\n",
    "#         \"scikit-learn==1.0.1\",\n",
    "#         \"xgboost==1.5.1\",\n",
    "#         \"google-cloud-storage==2.13.0\",\n",
    "#         \"google-cloud-aiplatform==1.3.0\"\n",
    "#     ],\n",
    "# )\n",
    "# def eval_model(\n",
    "#     test_set: Input[Dataset],\n",
    "#     xgb_model: Input[Model],\n",
    "#     metrics: Output[ClassificationMetrics],\n",
    "#     smetrics: Output[Metrics],\n",
    "#     project : str,\n",
    "#     region : str,) -> NamedTuple(\"Outputs\", [(\"deploy\", str)]):\n",
    "#     from xgboost import XGBClassifier\n",
    "#     import pandas as pd\n",
    "#     import joblib\n",
    "#     import logging\n",
    "    \n",
    "#     aiplatform.init(project=project, location=region)\n",
    "#     logging.basicConfig(level=logging.DEBUG)\n",
    "#     from google.cloud import storage\n",
    "\n",
    "#     logging.debug(\"MODEL URI \" + xgb_model.uri)\n",
    "#     logging.debug(\"MODEL PATH \" + xgb_model.path)\n",
    "    \n",
    "#     model_path = xgb_model.uri\n",
    "#     bucket= model_path.split(\"//\")[1] # remove gs://\n",
    "#     bucket = bucket.split(\"/\")[0]\n",
    "#     path = model_path.replace(\"gs://\"+bucket+\"/\", \"\")\n",
    "    \n",
    "#     logging.debug(\"CLOUD STORAGE \" + bucket)\n",
    "#     logging.debug(\"MODEL PATH \" + path)   \n",
    "    \n",
    "#     client = storage.Client()\n",
    "#     bucket = client.get_bucket(bucket)\n",
    "#     blob = bucket.blob(path + \"/model.bst\")\n",
    "#     with blob.open(mode=\"rb\") as file:\n",
    "#         model = joblib.load(file)\n",
    "        \n",
    "        \n",
    "#     data = pd.read_csv(test_set.path)\n",
    "#    # model = XGBClassifier()\n",
    "    \n",
    "    \n",
    "#     #model.load_model(xgb_model.path)\n",
    "#     # model = joblib.load(xgb_model.path)\n",
    "#     #model = joblib.load(xgb_model.uri)\n",
    "\n",
    "#     score = model.score(\n",
    "#         data.drop(columns=[\"target\"]),\n",
    "#         data.target,\n",
    "#     )\n",
    "\n",
    "#     from sklearn.metrics import roc_curve\n",
    "#     y_scores =  model.predict_proba(data.drop(columns=[\"target\"]))[:, 1]\n",
    "#     fpr, tpr, thresholds = roc_curve(\n",
    "#          y_true=data.target.to_numpy(), y_score=y_scores, pos_label=True\n",
    "#     )\n",
    "#     metrics.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n",
    "\n",
    "#     from sklearn.metrics import confusion_matrix\n",
    "#     y_pred = model.predict(data.drop(columns=[\"target\"]))\n",
    "\n",
    "#     metrics.log_confusion_matrix(\n",
    "#        [\"False\", \"True\"],\n",
    "#        confusion_matrix(\n",
    "#            data.target, y_pred\n",
    "#        ).tolist()\n",
    "#     )\n",
    "\n",
    "#     xgb_model.metadata[\"test_score\"] = float(score)\n",
    "#     smetrics.log_metric(\"score\", float(score))\n",
    "\n",
    "\n",
    "#     deploy = \"true\"\n",
    "#     #compare threshold or to previous\n",
    "\n",
    "#     return (deploy,)\n",
    "\n",
    "@component(\n",
    "    packages_to_install = [\n",
    "        \n",
    "        \"xgboost==1.6.2\",\n",
    "        \"pandas==1.3.5\",\n",
    "        \"joblib==1.1.0\",\n",
    "        \"scikit-learn==1.0.2\",\n",
    "        \"google-cloud-storage==2.13.0\",\n",
    "    ],\n",
    ")\n",
    "def eval_model(\n",
    "    test_set: Input[Dataset],\n",
    "    xgb_model: Input[Model],\n",
    "    metrics: Output[ClassificationMetrics],\n",
    "    smetrics: Output[Metrics],\n",
    "    bucket_name: str,\n",
    ") -> NamedTuple(\"Outputs\", [(\"deploy\", str)]):\n",
    "    from xgboost import XGBClassifier\n",
    "    import pandas as pd\n",
    "\n",
    "    data = pd.read_csv(test_set.path)\n",
    "    model = XGBClassifier()\n",
    "    \n",
    "    from google.cloud import storage\n",
    "    import joblib\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob_path = xgb_model.uri.replace(\"gs://\" + bucket_name + \"/\", \"\")\n",
    "    smetrics.log_metric(\"blob_path\", str(blob_path))\n",
    "\n",
    "    blob = bucket.blob(blob_path + \"/model.joblib\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    with blob.open(mode=\"rb\") as file:\n",
    "        model = joblib.load(file)\n",
    "    #model.load_model(xgb_model.path)\n",
    "    \n",
    "\n",
    "    score = model.score(\n",
    "        data.drop(columns=[\"target\"]),\n",
    "        data.target,\n",
    "    )\n",
    "\n",
    "    from sklearn.metrics import roc_curve\n",
    "    y_scores =  model.predict_proba(data.drop(columns=[\"target\"]))[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(\n",
    "         y_true=data.target.to_numpy(), y_score=y_scores, pos_label=True\n",
    "    )\n",
    "    metrics.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    y_pred = model.predict(data.drop(columns=[\"target\"]))\n",
    "\n",
    "    metrics.log_confusion_matrix(\n",
    "       [\"False\", \"True\"],\n",
    "       confusion_matrix(\n",
    "           data.target, y_pred\n",
    "       ).tolist()\n",
    "    )\n",
    "\n",
    "    xgb_model.metadata[\"test_score\"] = float(score)\n",
    "    smetrics.log_metric(\"score\", float(score))\n",
    "\n",
    "\n",
    "    deploy = \"true\"\n",
    "    #compare threshold or to previous\n",
    "\n",
    "    return (deploy,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc7444d1-93e8-45aa-8b7b-2674a7202515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform==1.25.0\"],\n",
    ")\n",
    "def deploy_xgboost_model(\n",
    "    model: Input[Model],\n",
    "    project_id: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model],\n",
    "):\n",
    "    \"\"\"Deploys an XGBoost model to Vertex AI Endpoint.\n",
    "\n",
    "    Args:\n",
    "        model: The model to deploy.\n",
    "        project_id: The project ID of the Vertex AI Endpoint.\n",
    "\n",
    "    Returns:\n",
    "        vertex_endpoint: The deployed Vertex AI Endpoint.\n",
    "        vertex_model: The deployed Vertex AI Model.\n",
    "    \"\"\"\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    aiplatform.init(project=project_id)\n",
    "\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"breast-cancer-xgb-classification\",\n",
    "        artifact_uri=model.uri,\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-6:latest\",\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "194b4eab-36ae-4e88-a16f-65d74f0bb3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME=\"gs://\" + PROJECT_ID + \"-bucket\"\n",
    "PIPELINE_ROOT = BUCKET_NAME + \"/pipeline_root/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "947dd179-3661-4223-8c83-b3b7a8ba5d04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32293/1289652284.py:16: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
      "  with dsl.Condition(\n"
     ]
    }
   ],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT + \"xgboost-pipeline-v2\",\n",
    "    # A name for the pipeline. Use to determine the pipeline Context.\n",
    "    name=\"xgboost-pipeline-with-deployment-v2\",\n",
    ")\n",
    "def pipeline():\n",
    "    dataset_op = get_data()\n",
    "    training_op = train_model(dataset = dataset_op.outputs[\"dataset_train\"])\n",
    "    eval_op = eval_model(\n",
    "        test_set=dataset_op.outputs[\"dataset_test\"],\n",
    "        xgb_model=training_op.outputs[\"model_artifact\"],\n",
    "        bucket_name = \"kubeflow-mlops-410520-bucket\"\n",
    "    )\n",
    "\n",
    "    with dsl.Condition(\n",
    "        eval_op.outputs[\"deploy\"] == \"true\",\n",
    "        name=\"deploy\",\n",
    "    ):\n",
    "\n",
    "      deploy_op = deploy_xgboost_model(model = training_op.outputs[\"model_artifact\"],\n",
    "                         project_id = PROJECT_ID,\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "55eb3abe-672c-4352-afb0-ee0d008fa0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"pipeline-breast-cancer.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "854993bb-6d76-4737-973d-135a7d1b4e94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import pipeline_jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4a7398b-7e7c-465e-9bc2-e03fddb74d59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# job = pipeline_jobs.PipelineJob(\n",
    "#     display_name=\"xgboost test\",\n",
    "#     template_path=\"xgb_pipeline.json\",\n",
    "#     enable_caching = False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dd3b639c-ecff-40a6-92a2-8a52f3926c76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/990864364836/locations/us-central1/pipelineJobs/xgboost-pipeline-with-deployment-v2-20240328202049\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/990864364836/locations/us-central1/pipelineJobs/xgboost-pipeline-with-deployment-v2-20240328202049')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/xgboost-pipeline-with-deployment-v2-20240328202049?project=990864364836\n",
      "PipelineJob projects/990864364836/locations/us-central1/pipelineJobs/xgboost-pipeline-with-deployment-v2-20240328202049 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/990864364836/locations/us-central1/pipelineJobs/xgboost-pipeline-with-deployment-v2-20240328202049 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/990864364836/locations/us-central1/pipelineJobs/xgboost-pipeline-with-deployment-v2-20240328202049 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/990864364836/locations/us-central1/pipelineJobs/xgboost-pipeline-with-deployment-v2-20240328202049 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/990864364836/locations/us-central1/pipelineJobs/xgboost-pipeline-with-deployment-v2-20240328202049 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/990864364836/locations/us-central1/pipelineJobs/xgboost-pipeline-with-deployment-v2-20240328202049 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "Timeout of 120.0s exceeded, last exception: 503 502:Bad Gateway",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1161\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1155\u001b[0m (\n\u001b[1;32m   1156\u001b[0m     state,\n\u001b[1;32m   1157\u001b[0m     call,\n\u001b[1;32m   1158\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1159\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1160\u001b[0m )\n\u001b[0;32m-> 1161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1004\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1004\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"502:Bad Gateway\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-03-28T20:30:29.365331964+00:00\", grpc_status:14, grpc_message:\"502:Bad Gateway\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: 503 502:Bad Gateway",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m job \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mPipelineJob(\n\u001b[1;32m      2\u001b[0m     display_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbreast-cancer-demo-pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     template_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline-breast-cancer.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     pipeline_root\u001b[38;5;241m=\u001b[39mPIPELINE_ROOT,\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:323\u001b[0m, in \u001b[0;36mPipelineJob.run\u001b[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run this configured PipelineJob and monitor the job until completion.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m        Optional. The timeout for the create request in seconds.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m network \u001b[38;5;241m=\u001b[39m network \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mnetwork\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreserved_ip_ranges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreserved_ip_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:863\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    862\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    866\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:366\u001b[0m, in \u001b[0;36mPipelineJob._run\u001b[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to ensure network synchronization and to run\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03mthe configured PipelineJob and monitor the job until completion.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m        Optional. The timeout for the create request in seconds.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    360\u001b[0m     service_account\u001b[38;5;241m=\u001b[39mservice_account,\n\u001b[1;32m    361\u001b[0m     network\u001b[38;5;241m=\u001b[39mnetwork,\n\u001b[1;32m    362\u001b[0m     reserved_ip_ranges\u001b[38;5;241m=\u001b[39mreserved_ip_ranges,\n\u001b[1;32m    363\u001b[0m     create_request_timeout\u001b[38;5;241m=\u001b[39mcreate_request_timeout,\n\u001b[1;32m    364\u001b[0m )\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:597\u001b[0m, in \u001b[0;36mPipelineJob._block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    594\u001b[0m multiplier \u001b[38;5;241m=\u001b[39m _WAIT_TIME_MULTIPLIER  \u001b[38;5;66;03m# scale wait by 2 every iteration\u001b[39;00m\n\u001b[1;32m    596\u001b[0m previous_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 597\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _PIPELINE_COMPLETE_STATES:\n\u001b[1;32m    598\u001b[0m     current_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_time \u001b[38;5;241m-\u001b[39m previous_time \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m log_wait:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:565\u001b[0m, in \u001b[0;36mPipelineJob.state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[gca_pipeline_state\u001b[38;5;241m.\u001b[39mPipelineState]:\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Current pipeline state.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sync_gca_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:699\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._sync_gca_resource\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sync_gca_resource\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    697\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sync GAPIC service representation of client class resource.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gca_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:692\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns GAPIC service representation of client class resource.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m        Should not include project and location.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m resource_name \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mfull_resource_name(\n\u001b[1;32m    682\u001b[0m     resource_name\u001b[38;5;241m=\u001b[39mresource_name,\n\u001b[1;32m    683\u001b[0m     resource_noun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_noun,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m     resource_id_validator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_id_validator,\n\u001b[1;32m    690\u001b[0m )\n\u001b[0;32m--> 692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getter_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_RETRY\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/pipeline_service/client.py:1697\u001b[0m, in \u001b[0;36mPipelineServiceClient.get_pipeline_job\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1697\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:221\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deadline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m next_sleep \u001b[38;5;241m>\u001b[39m deadline:\n\u001b[1;32m    216\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    217\u001b[0m         error_list,\n\u001b[1;32m    218\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mTIMEOUT,\n\u001b[1;32m    219\u001b[0m         original_timeout,\n\u001b[1;32m    220\u001b[0m     )\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    222\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying due to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, sleeping \u001b[39m\u001b[38;5;132;01m{:.1f}\u001b[39;00m\u001b[38;5;124ms ...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(error_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], next_sleep)\n\u001b[1;32m    224\u001b[0m )\n",
      "\u001b[0;31mRetryError\u001b[0m: Timeout of 120.0s exceeded, last exception: 503 502:Bad Gateway"
     ]
    }
   ],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"breast-cancer-demo-pipeline\",\n",
    "    template_path=\"pipeline-breast-cancer.yaml\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
