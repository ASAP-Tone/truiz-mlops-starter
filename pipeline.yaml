# PIPELINE DEFINITION
# Name: xgboost-pipeline-with-deployment-v2
# Outputs:
#    eval-model-metrics: system.ClassificationMetrics
#    eval-model-smetrics: system.Metrics
components:
  comp-condition-1:
    dag:
      tasks:
        deploy-xgboost-model:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-deploy-xgboost-model
          inputs:
            artifacts:
              model:
                componentInputArtifact: pipelinechannel--train-model-model_artifact
            parameters:
              project_id:
                runtimeValue:
                  constant: kubeflow-mlops-410520
          taskInfo:
            name: deploy-xgboost-model
    inputDefinitions:
      artifacts:
        pipelinechannel--train-model-model_artifact:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        pipelinechannel--eval-model-deploy:
          parameterType: STRING
  comp-deploy-xgboost-model:
    executorLabel: exec-deploy-xgboost-model
    inputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
          description: The model to deploy.
      parameters:
        project_id:
          description: The Google Cloud project ID.
          parameterType: STRING
  comp-eval-model:
    executorLabel: exec-eval-model
    inputDefinitions:
      artifacts:
        test_set:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        xgb_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        bucket_name:
          parameterType: STRING
        score_threshold:
          defaultValue: 0.8
          isOptional: true
          parameterType: NUMBER_DOUBLE
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.ClassificationMetrics
            schemaVersion: 0.0.1
        smetrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
      parameters:
        deploy:
          parameterType: STRING
  comp-get-data:
    executorLabel: exec-get-data
    inputDefinitions:
      parameters:
        project_id:
          description: str
          parameterType: STRING
    outputDefinitions:
      artifacts:
        dataset_test:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        dataset_train:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-train-model:
    executorLabel: exec-train-model
    inputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: Input[Dataset] the training set.
    outputDefinitions:
      artifacts:
        model_artifact:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
defaultPipelineRoot: gs://kubeflow-mlops-410520-bucket/pipeline_root/xgboost-pipeline-v2
deploymentSpec:
  executors:
    exec-deploy-xgboost-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - deploy_xgboost_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform==1.25.0'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef deploy_xgboost_model(\n    model: Input[Model],\n    project_id:\
          \ str,\n    # region: str = \"us-central1\",  # Optional, default to a common\
          \ region\n    #endpoint_display_name: str = \"breast-cancer-xgb-classification\"\
          ,\n    #machine_type: str = \"n1-standard-4\",\n    # vertex_endpoint: Output[Artifact],\n\
          \    # vertex_model: Output[Model],\n) -> None:\n    \"\"\"Deploys an XGBoost\
          \ model to Vertex AI Endpoint.\n\n    Args:\n        model: The model to\
          \ deploy.\n        project_id: The Google Cloud project ID.\n        vertex_endpoint:\
          \ Output[Artifact] representing the deployed Vertex AI Endpoint.\n     \
          \   vertex_model: Output[Model] representing the deployed Vertex AI Model.\n\
          \    \"\"\"\n\n    from google.cloud import aiplatform\n\n    # Initialize\
          \ AI Platform with project \n    aiplatform.init(project=project_id)\n\n\
          \    # Upload the Model\n    deployed_model = aiplatform.Model.upload(\n\
          \        display_name=\"xgb-classification\",\n        artifact_uri=model.uri,\n\
          \        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-6:latest\"\
          ,\n    )\n\n    # Deploy the Model to an Endpoint\n    endpoint = deployed_model.deploy(machine_type=\"\
          n1-standard-4\")\n\n    # Save Outputs\n    vertex_endpoint.uri = endpoint.resource_name\n\
          \    vertex_model.uri = deployed_model.resource_name\n\n"
        image: python:3.8
    exec-eval-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - eval_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.6.2'\
          \ 'pandas==1.3.5' 'joblib==1.1.0' 'scikit-learn==1.0.2' 'google-cloud-storage==2.13.0'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef eval_model(\n    test_set: Input[Dataset],\n    xgb_model: Input[Model],\n\
          \    metrics: Output[ClassificationMetrics],\n    smetrics: Output[Metrics],\n\
          \    bucket_name: str,\n    score_threshold: float = 0.8,\n) -> NamedTuple(\"\
          Outputs\", [(\"deploy\", str)]):\n\n    from google.cloud import storage\n\
          \    import joblib\n    import pandas as pd\n    from sklearn.metrics import\
          \ roc_curve, confusion_matrix\n    from collections import namedtuple\n\n\
          \n    # ----- 1. Load Test Data and Model -----\n    data = pd.read_csv(test_set.path)\n\
          \n    client = storage.Client()\n    bucket = client.get_bucket(bucket_name)\n\
          \    blob_path = xgb_model.uri.replace(f\"gs://{bucket_name}/\", \"\")\n\
          \    smetrics.log_metric(\"blob_path\", str(blob_path))\n\n    blob = bucket.blob(f\"\
          {blob_path}/model.joblib\")\n    with blob.open(mode=\"rb\") as file:\n\
          \        model = joblib.load(file)\n\n    # ----- 2. Evaluation and Metrics\
          \ -----\n    y_scores = model.predict_proba(data.drop(columns=[\"will_buy_on_return_visit\"\
          ]))[:, 1]\n    y_pred = model.predict(data.drop(columns=[\"will_buy_on_return_visit\"\
          ]))\n    score = model.score(data.drop(columns=[\"will_buy_on_return_visit\"\
          ]), data.will_buy_on_return_visit)\n\n    fpr, tpr, thresholds = roc_curve(data.will_buy_on_return_visit.to_numpy(),\
          \ y_scores, pos_label=True)\n    metrics.log_roc_curve(fpr.tolist(), tpr.tolist(),thresholds.tolist())\n\
          \n    cm = confusion_matrix(data.will_buy_on_return_visit, y_pred)\n   \
          \ metrics.log_confusion_matrix([\"False\", \"True\"], cm.tolist())\n   \
          \ smetrics.log_metric(\"score\", float(score))\n\n    # ----- 3. Deployment\
          \ Decision Logic -----\n    deploy = \"true\" if score >= score_threshold\
          \ else \"false\"\n\n    # ----- 4. Metadata Update -----\n    xgb_model.metadata[\"\
          test_score\"] = float(score)\n\n    Outputs = namedtuple(\"Outputs\", [\"\
          deploy\"])\n    return Outputs(deploy)\n\n"
        image: python:3.8
    exec-get-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - get_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==1.3.4'\
          \ 'scikit-learn==1.0.1' 'google-cloud-bigquery==3.13.0' 'db-dtypes==1.1.1'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef get_data(\n    project_id: str,\n    dataset_train: Output[Dataset],\n\
          \    dataset_test: Output[Dataset],\n) -> None:\n\n    \"\"\" Loads data\
          \ from BigQuery, splits it into training and test sets,\n    and saves them\
          \ as CSV files.\n\n    Args:\n        project_id: str\n        dataset_train:\
          \ Output[Dataset] for the training set.\n        dataset_test: Output[Dataset]\
          \ for the test set.\n    \"\"\"\n\n    from sklearn import datasets\n  \
          \  from sklearn.model_selection import train_test_split\n    import pandas\
          \ as pd\n\n    from google.cloud import bigquery\n\n    # Construct a BigQuery\
          \ client object.\n    client = bigquery.Client(project= project_id)\n  \
          \  job_config = bigquery.QueryJobConfig()\n    query = \"\"\"\n\n      \
          \  SELECT\n      * EXCEPT(fullVisitorId)\n    FROM\n\n      # features\n\
          \      (SELECT\n        fullVisitorId,\n        IFNULL(totals.bounces, 0)\
          \ AS bounces,\n        IFNULL(totals.timeOnSite, 0) AS time_on_site\n  \
          \    FROM\n        `data-to-insights.ecommerce.web_analytics`\n      WHERE\n\
          \        totals.newVisits = 1\n        AND date BETWEEN '20160801' AND '20170430')\
          \ # train on first 9 months\n      JOIN\n      (SELECT\n        fullvisitorid,\n\
          \        IF(COUNTIF(totals.transactions > 0 AND totals.newVisits IS NULL)\
          \ > 0, 1, 0) AS will_buy_on_return_visit\n      FROM\n          `data-to-insights.ecommerce.web_analytics`\n\
          \      GROUP BY fullvisitorid)\n      USING (fullVisitorId)\n      LIMIT\
          \ 10000\n    ;\n    \"\"\"\n\n    query_job = client.query(query, job_config=job_config)\n\
          \    df = query_job.to_dataframe()\n\n    # Split Data\n    train, test\
          \ = train_test_split(df, test_size=0.3, random_state=42)\n\n    # Save to\
          \ Outputs\n    train.to_csv(dataset_train.path, index=False)\n    test.to_csv(dataset_test.path,\
          \ index=False)\n\n"
        image: python:3.8
    exec-train-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.6.2'\
          \ 'pandas==1.3.5' 'joblib==1.1.0' 'scikit-learn==1.0.2' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_model(\n    dataset: Input[Dataset],\n    model_artifact:\
          \ Output[Model], \n) -> None:\n\n    \"\"\" Loads training csv, fits model,\n\
          \    and saves a model artifact to a path.\n\n    Args:\n        dataset:\
          \ Input[Dataset] the training set.\n        model_artifact: Output[Model]\
          \ for the test set.\n    \"\"\"\n    import os\n    import joblib\n    import\
          \ pandas as pd\n    from xgboost import XGBClassifier\n\n    # Load Training\
          \ Data\n    data = pd.read_csv(dataset.path)\n\n    # Train XGBoost Model\n\
          \    model = XGBClassifier(objective=\"binary:logistic\")\n    model.fit(data.drop(columns=[\"\
          will_buy_on_return_visit\"]), data.will_buy_on_return_visit)\n\n    # Evaluate\
          \ and Log Metrics\n    score = model.score(data.drop(columns=[\"will_buy_on_return_visit\"\
          ]), data.will_buy_on_return_visit)\n\n    # Save the Model Artifact\n  \
          \  os.makedirs(model_artifact.path, exist_ok=True)\n    joblib.dump(model,\
          \ os.path.join(model_artifact.path, \"model.joblib\"))\n\n    # Metadata\
          \ for the Artifact\n    model_artifact.metadata[\"train_score\"] = float(score)\n\
          \    model_artifact.metadata[\"framework\"] = \"XGBoost\"\n\n"
        image: python:3.8
pipelineInfo:
  name: xgboost-pipeline-with-deployment-v2
root:
  dag:
    outputs:
      artifacts:
        eval-model-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: eval-model
        eval-model-smetrics:
          artifactSelectors:
          - outputArtifactKey: smetrics
            producerSubtask: eval-model
    tasks:
      condition-1:
        componentRef:
          name: comp-condition-1
        dependentTasks:
        - eval-model
        - train-model
        inputs:
          artifacts:
            pipelinechannel--train-model-model_artifact:
              taskOutputArtifact:
                outputArtifactKey: model_artifact
                producerTask: train-model
          parameters:
            pipelinechannel--eval-model-deploy:
              taskOutputParameter:
                outputParameterKey: deploy
                producerTask: eval-model
        taskInfo:
          name: deploy
        triggerPolicy:
          condition: inputs.parameter_values['pipelinechannel--eval-model-deploy']
            == 'true'
      eval-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-eval-model
        dependentTasks:
        - get-data
        - train-model
        inputs:
          artifacts:
            test_set:
              taskOutputArtifact:
                outputArtifactKey: dataset_test
                producerTask: get-data
            xgb_model:
              taskOutputArtifact:
                outputArtifactKey: model_artifact
                producerTask: train-model
          parameters:
            bucket_name:
              runtimeValue:
                constant: kubeflow-mlops-410520-bucket
        taskInfo:
          name: eval-model
      get-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-get-data
        inputs:
          parameters:
            project_id:
              runtimeValue:
                constant: kubeflow-mlops-410520
        taskInfo:
          name: get-data
      train-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-model
        dependentTasks:
        - get-data
        inputs:
          artifacts:
            dataset:
              taskOutputArtifact:
                outputArtifactKey: dataset_train
                producerTask: get-data
        taskInfo:
          name: train-model
  outputDefinitions:
    artifacts:
      eval-model-metrics:
        artifactType:
          schemaTitle: system.ClassificationMetrics
          schemaVersion: 0.0.1
      eval-model-smetrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
schemaVersion: 2.1.0
sdkVersion: kfp-2.7.0
